{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08-Sentiments.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9fjV2dALrvb"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxmcgnZeNAB-"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "pipe = pipeline('text-classification', model=model_name,\n",
        "                 tokenizer=model_name) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co7tPg9LNUcr"
      },
      "source": [
        "pipe(\"Heute ist ein furchtbarer Tag\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uqcvec7Nh-O"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sFRTI5pOLEt"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "\n",
        "\n",
        "# das Modell muss zum Tokenizer passen!\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False # wir benötigen keine Embeddings\n",
        ")\n",
        "# hier evtl. model.cpu() einsetzen\n",
        "model.cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ObcHQwXOdEi"
      },
      "source": [
        "import pandas as pd\n",
        "at = pd.DataFrame([{ \"text\": \"Heute ist ein furchtbarer Tag\"}, {\"text\": \"Heute ist ein wunderschöner Tag\"}])\n",
        "at"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obuQws4oON8S"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "scores = []\n",
        "for i in tqdm(range(len(at)//100 + 1)):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for t in at[i*100:(i+1)*100][\"text\"].map(str).values:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            t,\n",
        "                            add_special_tokens = True,    # '[CLS]' und '[SEP]'\n",
        "                            max_length = 64,\n",
        "                            truncation = True,\n",
        "                            padding='max_length',\n",
        "                            return_attention_mask = True,  # Attention-Masks erzeugen\n",
        "                            return_tensors = 'pt',         # pytorch-Tensoren als Ergebnis\n",
        "                       )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "        \n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)        \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        res = model(input_ids.to(device), attention_mask=attention_masks.to(device))\n",
        "        for r in res[0].cpu().detach().numpy():\n",
        "            scores.append(list(softmax(r)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PewSh4e_OtZ6"
      },
      "source": [
        "pd.DataFrame(scores, columns=range(1,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfsqZ0VOO2KT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}